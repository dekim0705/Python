# ğŸ“Œ ìŠ¤ì¼€ì¥´ë§ : ì£¼ê¸°ì ì¸ ì‘ì—…, ì¼íšŒì„± ì‘ì—…, í´ë¡  ì‘ì—…ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ì‘ì—…ì„ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë° ì‚¬ìš©

import schedule
import time
import requests
from bs4 import BeautifulSoup

def perform_web_crawling() :
    url = "http://www.naver.com"
    response = requests.get(url)
    if response.status_code == 200 :
        soup = BeautifulSoup(response.text, "html.parser")
    print(soup)

def job() :
    print("ì›¹ í¬ë¡¤ë§ì„ ìˆ˜í–‰ í•©ë‹ˆë‹¤.")
    perform_web_crawling()

# ë§¤ì¼ ì •í•´ì§„ ì‹œê°„ì— ë™ì‘ í•˜ë„ë¡ êµ¬í˜„
schedule.every().day.at("10:47").do(job)

while True :
    schedule.run_pending()
    time.sleep(1) # 1ì´ˆë™ì•ˆ ëŒ€ê¸°í–ˆë‹¤ê°€ ëŒê¸°~